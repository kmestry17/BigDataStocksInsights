# BigDataStocksInsights
"A centralized repository for comprehensive big data analytics and insights into the dynamic world of stock markets. Discover powerful data-driven strategies and deep market insights to make informed decisions and stay ahead in the ever-evolving realm of financial investments."
This project ğŸ“Š focuses on the comprehensive ingestion and analysis of large-scale stock market data using the Hadoop ecosystem. The workflow is designed to cover data ingestion from various sources, including direct file transfer, stream ingestion through Apache Flume, and data ingestion using Sqoop. Furthermore, the project includes detailed data analysis using Pig ğŸ· and Hive/Impala ğŸ to derive meaningful insights from the ingested datasets.

ğŸ”§ Project Structure

The project is divided into the following major steps:

VM Setup ğŸ–¥ï¸

This initial step involves setting up the virtual machine (VM) and configuring it for the subsequent data ingestion and analysis tasks. It includes instructions for setting up Hadoop services, changing the Python default interpreter, and installing necessary packages.

Data Ingestion ğŸ“¥

This step covers the ingestion of data from different sources into HDFS using various methods and tools from the Hadoop ecosystem. It involves direct file transfer, stream ingestion using Apache Flume, and data ingestion using Sqoop.

Data Analysis ğŸ“ˆ

In this step, the ingested data is analyzed using Pig and Hive/Impala to derive valuable insights. The analysis includes tasks such as summarizing the dataset, querying specific information, and extracting meaningful statistics from the data.
